

import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import numpy as np



from keras.models import Sequential
from keras.layers import GRU, Dense
from keras.layers import LSTM
from keras  import callbacks
from keras import optimizers
import tensorflow as tf



#data= pd.read_csv('KSEB14-18.csv')
from google.colab import files 
uploaded = files.upload() 


import io 
data = pd.read_csv('KSEB14-18.csv') 


data = data.set_index('timestamp')

data.describe()


data.isnull().sum()

print('Min', np.min(data))
print('Max', np.max(data))

scaler = MinMaxScaler(feature_range=(0, 1))
scaled = scaler.fit_transform(data)
print('Min', np.min(scaled))
print('Max', np.max(scaled))


######## creating train and tests
#train_size = int(len(scaled) * 0.86)
train_size = 43103
test_size =  43824
#print(train_size)
#test_size = len(scaled - train_size)
train, test = scaled[0:train_size, :], scaled[train_size :, :]
print('train: {}\ntest: {}'.format(len(train), len(test)))

#This default will create a dataset where X is the energy quantity at a given time (t) and Y is the qty of energy at the next time (t + 1)

def create_dataset(data, look_back=1):
    print(len(data), look_back)
    dataX, dataY = [], []
    for i in range(len(data)-look_back-1):
        a = data[i:(i+look_back), 0]
        print(i)
        print('X {} to {}'.format(i, i+look_back))
        print(a)
        print('Y {}'.format(i + look_back))
        print(data[i + look_back, 0])
        data[i + look_back, 0]
        dataX.append(a)
        dataY.append(data[i + look_back, 0])
    return np.array(dataX), np.array(dataY)



look_back = 2
X_train, y_train = create_dataset(train, look_back)
X_test, y_test = create_dataset(test, look_back)


df_X_test = pd.DataFrame(X_test)
df_X_test.to_csv('x_test_df.csv',index= False)


x_test_df = pd.read_csv("/home/anthony/PycharmProjects/first_project/x_test_df.csv")

X_test = x_test_df.as_matrix()


len(X_test)


X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
X_test



X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
print(X_train.shape)
print(X_test.shape)


# In[ ]:


# The network has a visible layer with 1 input, a hidden layer with 8 LSTM blocks or neurons, and an output layer that makes a single value prediction. The default sigmoid activation function is used for the LSTM blocks. The network is trained for 200 epochs and a batch size of 1 is used.

#create and fit the LSTM network



batch_size = 1
model1 = Sequential()
model1.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))
model1.add(Dense(1))
model1.compile(loss='mean_squared_error', optimizer='adam',metrics=['acc'])
model1.fit(X_train, y_train, epochs=300, batch_size=batch_size, verbose=2, shuffle=True)

\

import pickle
model1 = pickle.load(open("/home/anthony/PycharmProjects/first_project/model_uni_final_new.dat", "rb"))





testPredict = model1.predict(X_test)


testPredict = scaler.inverse_transform(testPredict)


predict_df = pd.DataFrame(testPredict,columns=['demand'])
predict_df.head()
#len(predict_df)

predict_df.to_csv('pred_df_final.csv')

import math
from sklearn.metrics import mean_squared_error

trainPredict = model1.predict(X_train, batch_size=batch_size)
model1.reset_states()

testPredict = model1.predict(X_test, batch_size=batch_size)
# invert predictions
trainPredict = scaler.inverse_transform(trainPredict)
y_train = scaler.inverse_transform([y_train])
testPredict = scaler.inverse_transform(testPredict)
y_test = scaler.inverse_transform([y_test])
# calculate root mean squared error
trainScore = math.sqrt(mean_squared_error(y_train[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(y_test[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

trainPredictPlot = np.empty_like(scaled)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict
# shift test predictions for plotting
testPredictPlot = np.empty_like(scaled)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(scaled)-1, :] = testPredict
# plot baseline and predictions
plt.figure(figsize=(30,10))
plt.plot(scaler.inverse_transform(scaled))
#plt.plot(trainPredictPlot)
#plt.plot(scaler.inverse_transform(y_test))
plt.plot(testPredictPlot)
plt.show()



testpredict_df = pd.DataFrame(testPredict)

testpredict_df.head()

